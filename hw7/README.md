# W251 - Summer 2020
## Homework 7
## Tom Goter

For homework 7 we were to repeat homework 3, but replace the openCv face detection with a deep learning model. I did this using the detectnet framework from [Jetson Inference](https://github.com/dusty-nv/jetson-inference). DetectNet allows the user to specify what pretrained network to use at runtime as well as what camera device to use so it was a natural go-to for this application. One of the pretrained models is FaceNet - again it seemed like the obvious choice. Normally detectNet.py would find the bounding box and overlay it on the entire capture frame. Since we want cropped faces, I needed to get the bounding box coordinates, convert the detection object to numpy array, and mask out the face region. You can see how I did this in the detectnet.py file which is a modified version of the one found at dusty-nv/jetson-inference.

I was able to dockerize the python script using the dockerfiles/FD.Dockerfile. I built an image from the tensorrt base image and installed jetson-inference. I then ran the image with the following command: `do docker run -e DISPLAY=$DISPLAY --privileged --env QT_X11_NO_MITSHM=1 --rm -it --device=/dev/video0 -v/tmp/.X11-unix:/tmp/.X11-unix:rw -v /home/tom/w251/w251/hw7/detectnet:/detectnet fdnn:v1`. In doing so I passed both the camera device and the folder with the detectnet python script and pretrained network files as a volume. The python script was executed interactively in the docker container. The camera was successfully loaded, but I struggled to get the output to display. I spent a good deal of time on this, and am now giving up to focus on the final project.
