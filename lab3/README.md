 # W251 - Summer 2020 - Lab 3
 ## Part 1
 The objective of part 1 of lab 3 is to obtain the GPU temperature from our jetson device, pass it through our MQTT broker to the cloud. In practice I have implemented it to pass the message to our forwarding broker, but I do not forward to the cloud as that is a trivial excercise after getting through HW3. In order to determine the GPU temperature, we can simply run tegrastats command which comes with our Jetson OS. In practice I run this command in the bakground and dump to a log file every second. I then read the last line from this file in an infinite loop and extract the temperature through a simple string search. We then pass this through to our MQTT broker. This is all done in a simple Python script which you can find at context/gpu_temp.py. TThis file is exectuted in our own docker container. The image for this container is created using the following command: `docker build -t gputemp:v1 -f dockerfiles/GPUTemp.Dockerfile context`. This creates the gputemp:v1 image. We then use this image to spin up a docker container on our docker network with the following command: `docker run --rm -ti --network=hw03 gputemp:v1`.This script expects our MQTT broker to be up already on a docker network. To spin up our MQTT broker we simply use the command: `docker run --name=mosquitto --network hw03 -p 1883:1883 -ti --rm mosquitto`. To confirm that our messages are being sent to our broker, we also create another container which simply subscribes to our new topic and prints out the messages that are received. In order to do this we use the dockerfile dockerfiles/TempCatch.Dockerfile which makes use of the simply python script context/catch.py in order to print out our messages. We create the docker image using the following line: `docker build -t catchapp:v1 -f dockerfiles/TempCatch.Dockerfile context` and then spin this container up using: `docker run --rm -ti --network=hw03 catchapp:v1`. When all goes well, you will see a message in the terminal where your third and final docker container is running every second.
 
 
 ## Part 2
 Motion detection instead of face capture. Same concept as homework 3 though. Implemented the motiona capture with blur using cv2 package in python (same as the facial capture). This time we use methods:
 - createBackgroundSubtractorMOG2()
 - blur()  
The first method tries to remove the background from a frame or image. In our case we are streaming from a webcam and grabbing frames. We apply the createBackgroundSubtractorMOG2() method first which results in what resembles a negative. The blur function is then called with the specified 3,3 kernel. All this does is apply a gaussian blur to neiboring pixels and results in a smoothed image. We implement these methods sequentially in the context/face_blur.py script. This script is then added to a docker container called blurapp:v1 using the dockerfiles/Blur.Dockerfile which is an exact copy of FD.Dockerfile used for HW3 except it uses face_blur.py insetead of face_detectory.py.  
Image Built with `docker build -t blurapp:v1 -f dockerfiles/Blur.Dockerfile context`Our aplication is executed by first running a MQQT broker (not absolutely necessary but our python script assumes it is up and running) on a local network - in our case we do this using the mosquitto docker image we created for HW3 using the following command: `docker run --name=mosquitto --network hw03 -p 1883:1883 -ti --rm mosquitto` then we spin up our blurapp docker container using the following command
`xhost local:root
docker run -e DISPLAY=$DISPLAY --rm --privileged --env QT_X11_NO_MITSHM=1 -v /tmp/.X11-unix:/tmp/.X11-unix:rw --device /dev/video0 --network=hw03 -ti blurapp:v1`  

Voila! You should see a black and white image of yourself that responds to your movement.
 
